import streamlit as st
import requests
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup
import google.generativeai as genai
import sys
import time
import json
from PIL import Image
from io import BytesIO

# ================= AYARLAR =================
API_KEY = st.secrets["API_KEY"]
WP_USER = st.secrets["WP_USER"]
WP_PASS = st.secrets["WP_PASS"]
WEBSITE_URL = "https://yolpedia.eu" 
LOGO_URL = "https://yolpedia.eu/wp-content/uploads/2025/11/cropped-Yolpedia-Favicon-e1620391336469.png"
DATA_FILE = "yolpedia_data.json"
# ===========================================

# --- FAVICON ---
try:
    response = requests.get(LOGO_URL, timeout=5)
    favicon = Image.open(BytesIO(response.content))
except:
    favicon = "ü§ñ"

st.set_page_config(page_title="YolPedia Asistanƒ±", page_icon=favicon)

# --- BA≈ûLIK VE LOGO ---
st.markdown(
    f"""
    <style>
    .main-header {{
        display: flex;
        align-items: center;
        justify-content: center;
        margin-top: 20px;
        margin-bottom: 30px;
    }}
    .logo-img {{
        width: 90px;
        margin-right: 20px;
    }}
    .title-text {{
        font-size: 42px;
        font-weight: 700;
        margin: 0;
        color: #ffffff;
    }}
    @media (prefers-color-scheme: light) {{
        .title-text {{ color: #000000; }}
    }}
    </style>
    <div class="main-header">
        <img src="{LOGO_URL}" class="logo-img">
        <h1 class="title-text">YolPedia Asistanƒ±</h1>
    </div>
    """,
    unsafe_allow_html=True
)

genai.configure(api_key=API_KEY)

# --- MODELƒ∞ BUL ---
@st.cache_resource
def model_yukle():
    generation_config = {
        "temperature": 0.0,
        "max_output_tokens": 8192
    }
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if 'flash' in m.name.lower():
                    return genai.GenerativeModel(m.name, generation_config=generation_config)
        return genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)
    except:
        return None

model = model_yukle()

# --- VERƒ∞ Y√úKLEME ---
@st.cache_data(persist="disk", show_spinner=False)
def veri_yukle():
    try:
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            veriler = json.load(f)
        return veriler
    except FileNotFoundError:
        return []

# --- BA≈ûLANGI√á KONTROL√ú ---
if 'db' not in st.session_state:
    with st.spinner('Sistem ba≈ülatƒ±lƒ±yor...'):
        veriler = veri_yukle()
        if veriler:
            st.session_state.db = veriler
            st.success(f"‚úÖ Sistem Hazƒ±r! {len(veriler)} madde y√ºklendi.")
            time.sleep(1)
            st.rerun()
        else:
            st.error("‚ö†Ô∏è Veri dosyasƒ± (JSON) bulunamadƒ±! L√ºtfen GitHub'a y√ºkleyin.")

# --- YARDIMCI FONKSƒ∞YONLAR ---
def tr_normalize(metin):
    kaynak = "ƒüƒû√º√ú≈ü≈ûƒ±ƒ∞√∂√ñ√ß√á"
    hedef  = "gGuUsSiIoOcC"
    ceviri_tablosu = str.maketrans(kaynak, hedef)
    return metin.translate(ceviri_tablosu).lower()

def alakali_icerik_bul(soru, tum_veriler):
    gereksiz = ["nedir", "kimdir", "neredir", "nasil", "niye", "hangi", "kac", "ne", "ve", "ile", "bir", "bu", "su", "mi", "mu", "hakkinda", "bilgi", "almak", "istiyorum", "onun", "bunun", "suranin"]
    soru_temiz = tr_normalize(soru)
    anahtar = [k for k in soru_temiz.split() if k not in gereksiz and len(k) > 2]
    
    puanlanmis = []
    for veri in tum_veriler:
        baslik_norm = tr_normalize(veri['baslik'])
        icerik_norm = tr_normalize(veri['icerik'])
        
        puan = 0
        if soru_temiz in baslik_norm: puan += 50
        elif soru_temiz in icerik_norm: puan += 20
        
        for k in anahtar:
            if k in baslik_norm: puan += 3
            elif k in icerik_norm: puan += 1
        if puan > 0:
            puanlanmis.append({"veri": veri, "puan": puan})
    
    puanlanmis.sort(key=lambda x: x['puan'], reverse=True)
    en_iyiler = puanlanmis[:5]
    
    bulunanlar = ""
    kaynaklar = []
    for item in en_iyiler:
        v = item['veri']
        bulunanlar += f"\n--- BA≈ûLIK: {v['baslik']} ---\nƒ∞√áERƒ∞K:\n{v['icerik'][:10000]}\n"
        kaynaklar.append({"baslik": v['baslik'], "link": v['link']})
        
    return bulunanlar, kaynaklar

# --- SOHBET ARAY√úZ√ú ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Bir soru sorun..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        if 'db' in st.session_state and st.session_state.db:
            with st.spinner("üîé Ansiklopedi taranƒ±yor..."):
                time.sleep(0.3)
                baglam, kaynaklar = alakali_icerik_bul(prompt, st.session_state.db)
            
            # --- HAFIZA OLU≈ûTURMA (SON 4 MESAJ) ---
            gecmis_sohbet = ""
            # Son 4 mesajƒ± al (2 soru, 2 cevap) ki baƒülam kopmasƒ±n ama token dolmasƒ±n
            for msg in st.session_state.messages[-4:]:
                rol = "Kullanƒ±cƒ±" if msg['role'] == 'user' else "Asistan"
                # Kaynak linklerini hafƒ±zaya alma, kafasƒ±nƒ± karƒ±≈ütƒ±rƒ±r
                temiz_icerik = msg['content'].split("**üìö Kaynaklar:**")[0] 
                gecmis_sohbet += f"{rol}: {temiz_icerik}\n"
            
            # Baƒülam bo≈ü olsa bile ge√ßmi≈üe bakarak cevap verebilir mi kontrol et
            # (√ñrn: "Merhaba" dediƒüinde baƒülam bo≈ütur ama cevap vermelidir)
            
            try:
                # --- AKILLI VE HAFIZALI PROMPT ---
                full_prompt = f"""
                Sen YolPedia ansiklopedi asistanƒ±sƒ±n.
                
                G√ñREVƒ∞N:
                Sana verilen 'Bƒ∞LGƒ∞LER' metnini kullanarak soruyu en detaylƒ± ≈üekilde cevapla.
                A≈üaƒüƒ±daki 'GE√áMƒ∞≈û SOHBET' kƒ±smƒ±na bakarak konu≈ümanƒ±n akƒ±≈üƒ±nƒ± takip et.
                
                KURALLAR:
                1. Asla uydurma yapma, sadece verilen metinleri kullan.
                2. Cevaplarƒ± kƒ±sa tutma, detaylƒ± anlat.
                3. Eƒüer soru sohbete dayalƒ±ysa (√ñrn: 'Merhaba', 'Nasƒ±lsƒ±n'), kibarca yanƒ±t ver ve ansiklopediden ne sorabileceƒüini s√∂yle.
                4. Eƒüer ansiklopedik bir soruysa ve metinlerde cevap YOKSA, "√úzg√ºn√ºm, YolPedia ar≈üivinde bu konuyla ilgili net bir bilgi bulunmuyor." de.
                
                GE√áMƒ∞≈û SOHBET:
                {gecmis_sohbet}
                
                YENƒ∞ SORU: {prompt}
                
                YENƒ∞ SORU ƒ∞√áƒ∞N BULUNAN Bƒ∞LGƒ∞LER:
                {baglam if baglam else "Veri tabanƒ±nda bu kelimeyle ilgili √∂zel bir e≈üle≈üme bulunamadƒ±."}
                """
                
                stream = model.generate_content(full_prompt, stream=True)
                
                def stream_parser():
                    full_text = ""
                    for chunk in stream:
                        if chunk.text:
                            for word in chunk.text.split(" "):
                                yield word + " "
                                time.sleep(0.03)
                            full_text += chunk.text
                    
                    negatif = ["bulunmuyor", "bilmiyorum", "bilgi yok", "rastlanmamaktadƒ±r", "√ºzg√ºn√ºm", "maalesef"]
                    cevap_olumsuz = any(n in full_text.lower() for n in negatif)
                    
                    # Eƒüer baƒülam bulunduysa ve cevap olumluysa linkleri ekle
                    if baglam and kaynaklar and not cevap_olumsuz:
                        kaynak_metni = "\n\n**üìö Kaynaklar:**\n"
                        # Tekrar eden linkleri temizle
                        essiz_kaynaklar = {v['link']:v for v in kaynaklar}.values()
                        
                        for k in essiz_kaynaklar:
                            kaynak_metni += f"- [{k['baslik']}]({k['link']})\n"
                        
                        for line in kaynak_metni.split("\n"):
                            yield line + "\n"
                            time.sleep(0.1)

                response = st.write_stream(stream_parser)
                st.session_state.messages.append({"role": "assistant", "content": response})

            except Exception as e:
                st.error(f"Hata: {e}")
        else:
            st.error("Veri tabanƒ± y√ºklenemedi.")

# --- YAN MEN√ú ---
with st.sidebar:
    st.header("‚öôÔ∏è Y√∂netim")
    
    if st.button("üîÑ √ñnbelleƒüi Temizle"):
        st.cache_data.clear()
        st.rerun()
        
    st.divider()
    
    if 'db' in st.session_state:
        st.write(f"üìä Toplam ƒ∞√ßerik: {len(st.session_state.db)}")
        
        # --- M√úFETTƒ∞≈û ---
        st.divider()
        st.subheader("üïµÔ∏è Veri M√ºfetti≈üi")
        test_arama = st.text_input("Veri tabanƒ±nda ara:", placeholder="√ñrn: Otman Baba")
        
        if test_arama:
            bulunan_sayisi = 0
            norm_aranan = tr_normalize(test_arama)
            for v in st.session_state.db:
                norm_baslik = tr_normalize(v['baslik'])
                norm_icerik = tr_normalize(v['icerik'])
                if norm_aranan in norm_baslik or norm_aranan in norm_icerik:
                    st.success(f"‚úÖ {v['baslik']}")
                    bulunan_sayisi += 1
                    if bulunan_sayisi >= 5: break
            if bulunan_sayisi == 0:
                st.error("‚ùå Bu kelime veritabanƒ±nda yok!")
        # ----------------
        st.divider()
        if st.checkbox("T√ºm Ba≈ülƒ±klarƒ± G√∂r"):
            for item in st.session_state.db:
                st.text(item['baslik'])
